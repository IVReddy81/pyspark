{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMNopI+lRex1FfS54+pNvlP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IVReddy81/pyspark/blob/main/Struct%20type.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
        "schema1=StructType([StructField(\"id\",IntegerType(),False),\n",
        "                   StructField(\"name\",StringType(),True),\n",
        "                   StructField(\"cost\",IntegerType(),True)])\n",
        "data1=[(1,\"king\",100),(2,\"king1\",200)]\n",
        "df1=spark.createDataFrame(data1,schema1)\n",
        "df1.show()\n",
        "df1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45gqsg3BK1fp",
        "outputId": "536d87bc-b340-4465-8d43-3bd218c97b8e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----+\n",
            "| id| name|cost|\n",
            "+---+-----+----+\n",
            "|  1| king| 100|\n",
            "|  2|king1| 200|\n",
            "+---+-----+----+\n",
            "\n",
            "root\n",
            " |-- id: integer (nullable = false)\n",
            " |-- name: string (nullable = true)\n",
            " |-- cost: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
        "schema2=StructType([StructField(\"id\",IntegerType(),False),\n",
        "                   StructField(\"name\",StructType([StructField(\"id1\",StringType(),True),\n",
        "                                                 StructField(\"id2\",StringType(),True)]),True),\n",
        "                   StructField(\"cost\",IntegerType(),True)])\n",
        "data2=[(1,(\"2\",\"3\"),100),(2,(\"4\",\"6\"),200)]\n",
        "df2=spark.createDataFrame(data2,schema2)\n",
        "df2.show()\n",
        "df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TX_82LfL8yf",
        "outputId": "aa826611-7852-46b3-96ff-45e446c9065a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----+\n",
            "| id|  name|cost|\n",
            "+---+------+----+\n",
            "|  1|{2, 3}| 100|\n",
            "|  2|{4, 6}| 200|\n",
            "+---+------+----+\n",
            "\n",
            "root\n",
            " |-- id: integer (nullable = false)\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- id1: string (nullable = true)\n",
            " |    |-- id2: string (nullable = true)\n",
            " |-- cost: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import Row\n",
        "per=Row(\"n1\",\"n2\",\"n3\")\n",
        "data3=[per(1,\"ki\",3),per(2,\"jk\",4),per(4,\"fgyu\",7)]\n",
        "df3=spark.createDataFrame(data3)\n",
        "df3.show()\n",
        "df3.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwoGLaTUMr-v",
        "outputId": "ac90798e-2e90-453b-e45a-435da6baadaa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+---+\n",
            "| n1|  n2| n3|\n",
            "+---+----+---+\n",
            "|  1|  ki|  3|\n",
            "|  2|  jk|  4|\n",
            "|  4|fgyu|  7|\n",
            "+---+----+---+\n",
            "\n",
            "root\n",
            " |-- n1: long (nullable = true)\n",
            " |-- n2: string (nullable = true)\n",
            " |-- n3: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import Row\n",
        "per2=[Row(n1=\"jk\",n2=(Row(2,3)),n3=8),\n",
        "     Row(n1=\"hj\",n2=(Row(7,8)),n3=9)]\n",
        "df4=spark.createDataFrame(per2)\n",
        "df4.show()\n",
        "df4.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0ympPuMNWcC",
        "outputId": "ba8b98d2-d17d-4456-b24e-96c061bac7de"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+\n",
            "| n1|    n2| n3|\n",
            "+---+------+---+\n",
            "| jk|{2, 3}|  8|\n",
            "| hj|{7, 8}|  9|\n",
            "+---+------+---+\n",
            "\n",
            "root\n",
            " |-- n1: string (nullable = true)\n",
            " |-- n2: struct (nullable = true)\n",
            " |    |-- _1: long (nullable = true)\n",
            " |    |-- _2: long (nullable = true)\n",
            " |-- n3: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.withColumnRenamed(\"n1\",\"e2\").show() #renaming column from n1 to e2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS8KGSLIQWPF",
        "outputId": "a9b11cc6-8d72-40e4-fa1a-11bc266bcb63"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+---+\n",
            "| e2|  n2| n3|\n",
            "+---+----+---+\n",
            "|  1|  ki|  3|\n",
            "|  2|  jk|  4|\n",
            "|  4|fgyu|  7|\n",
            "+---+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.withColumn(\"n3\",(df3.n3)*10).show()  #n3=>n3*10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnhRJPL_QYss",
        "outputId": "e12bdafb-ef70-4644-b59b-d313caba047c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+---+\n",
            "| n1|  n2| n3|\n",
            "+---+----+---+\n",
            "|  1|  ki| 30|\n",
            "|  2|  jk| 40|\n",
            "|  4|fgyu| 70|\n",
            "+---+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit\n",
        "df6=df3.withColumn(\"n4\",lit(\"10\"))  #creating new column and assigning constant value\n",
        "df6.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emE12UzxQmax",
        "outputId": "5d94da59-9675-442c-e411-4fb669928245"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+---+---+\n",
            "| n1|  n2| n3| n4|\n",
            "+---+----+---+---+\n",
            "|  1|  ki|  3| 10|\n",
            "|  2|  jk|  4| 10|\n",
            "|  4|fgyu|  7| 10|\n",
            "+---+----+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col=[\"i1\",\"i2\",\"i3\",\"i4\"]\n",
        "from pyspark.sql.types import Row\n",
        "per=Row(\"n1\",\"n2\",\"n3\",\"n4\")\n",
        "data3=[per(1,\"ki\",3,3),per(2,\"jk\",4,6),per(4,\"fgyu\",7,9),per(7,\"rt\",20,10)]\n",
        "df5=spark.createDataFrame(data3,col)\n",
        "df5.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKH5Lh-CRD3j",
        "outputId": "612cc83f-c9ff-4ced-c495-ab14214cc608"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+---+---+\n",
            "| i1|  i2| i3| i4|\n",
            "+---+----+---+---+\n",
            "|  1|  ki|  3|  3|\n",
            "|  2|  jk|  4|  6|\n",
            "|  4|fgyu|  7|  9|\n",
            "|  7|  rt| 20| 10|\n",
            "+---+----+---+---+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}